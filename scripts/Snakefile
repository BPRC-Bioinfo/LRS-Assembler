# LRS-Assembly
# v 0.0.4
# By Giang Le & Jaimy


import os
import glob
import pandas as pd
from pathlib import Path

configfile: "configs/run-config.yaml"

SPECIES=config['species'].replace(" ", "_")
REGIONS = config['region']

NSAMPLES = list(config["nanopore"].keys())
PSAMPLES = list(config["pacbio"].keys())

SAMPLES = list(set(NSAMPLES) & set(PSAMPLES))

print ("LRS-Assembler")
print (f"Samples detected {SAMPLES}")

REFERENCE = list(set(config["reference"].keys()))

print (f"Reference detected {REFERENCE}")

wildcard_constraints:
    sample="|".join(SAMPLES),
    hap = "hap1|hap2",
    ref = "|".join(REFERENCE)

KVALS = [24,32,40]
WVALS = [100, 250, 500]

for sample, nano_dir in config['nanopore'].items():
    print (f"For {sample} nanopore:")
    for input_dir in nano_dir:
        fastq_gz_files = glob.glob(os.path.join(input_dir, "*.fastq.gz"))
        num_files = len(fastq_gz_files)

        if num_files > 0:
            print(f"Found {num_files} fastq.gz files in {input_dir}.")
        else:
            print(f"Warning: No fastq.gz files found at {input_dir}.")

for sample, pac_dir in config['pacbio'].items():
    print (f"For {sample} pacbio:")   
    for input_dir in pac_dir:
        bam_files = glob.glob(os.path.join(input_dir, "*.bam"))
        pbi_files = glob.glob(os.path.join(input_dir, "*.bam.pbi"))
        num_bam_files = len(bam_files)
        num_pbi_files = len(pbi_files)

        if num_bam_files > 0 and num_pbi_files > 0:
            print(f"Found {num_bam_files} BAM file(s) and {num_pbi_files} PBI file(s) in {input_dir}.")
        elif num_bam_files > 0:
            print(f"Found {num_bam_files} BAM file(s), but no PBI files in {input_dir}. ")
        elif num_pbi_files > 0:
            print(f"Found {num_pbi_files} PBI file(s), but no BAM files in {input_dir}.")
        else:
            print(f"Warning: No BAM or PBI files found at {input_dir}.")

rule all:
    input:
        expand("results/{sample}/info/{sample}_{ref}_{species}_report.html", sample = SAMPLES, species = SPECIES, ref = REFERENCE),

def check_library(region_name, library):
    library_path = Path(library)
    if not library_path.is_file():
        print(f"Error: Library file not found at {library} for region {region_name}")
        sys.exit(1)
    return library

rule prepare_genome_reference:
    output:
        genome = "reference/{ref}.fna",
    conda:
        "../envs/datasets.yaml"
    retries: 3
    params:
        genome = lambda wildcards: config["reference"][wildcards.ref]['genome'],
        ref = lambda wildcards: config["reference"][wildcards.ref]['accession_number'],
        zipfile = "{ref}_genome.zip",
    shell:
        """
        if [ -z "{params.genome}" ] || [ ! -f "{params.genome}" ]; then
            echo "Genome file not found locally, downloading from NCBI"
            datasets download genome accession {params.ref} --filename {params.zipfile} --include genome || (echo "Warning: download genome failed. Check accession or prepare the genome locally.")
            unzip {params.zipfile} -d "{params.ref}_fna"
            mv {params.ref}_fna/ncbi_dataset/data/{params.ref}/{params.ref}*.fna {output.genome}
            rm -r {params.zipfile} {params.ref}_fna
        else
            echo "Using local genome file {params.genome}"
            cp {params.genome} {output.genome}
        fi
        echo "Complete prepare_genome_reference"
        """

rule prepare_gff_reference:
    output:
        gff = "reference/{ref}.gff",
    conda:
        "../envs/datasets.yaml"
    retries: 3
    params:
        ref = lambda wildcards: config["reference"][wildcards.ref]['accession_number'],
        gff = lambda wildcards: config["reference"][wildcards.ref]['gff'],
        zipfile = "{ref}_gff.zip",
    shell:
        """
        if [ -z "{params.gff}" ] || [ ! -f "{params.gff}" ]; then
            echo "Gff file not found locally, downloading from NCBI"
            datasets download genome accession {params.ref} --filename {params.zipfile} --include gff3 || (echo "Warning: download gff failed. Check accession or prepare locally.")
            unzip {params.zipfile} -d "{params.ref}_gff"
            mv {params.ref}_gff/ncbi_dataset/data/{params.ref}/genomic.gff {output.gff}
            rm -r {params.zipfile} {params.ref}_gff
        else
            echo "Using local genome file {params.gff}"
            cp {params.gff} {output.gff}
        fi
        echo "Complete prepare_gff_reference"
        """

rule prepare_chromosome_reference:
    output:
        info = "reference/{ref}.info",
    retries: 3
    conda:
        "../envs/datasets.yaml"
    params:
        ref = lambda wildcards: config["reference"][wildcards.ref]['accession_number'],
        info = lambda wildcards: config["reference"][wildcards.ref]['chr_info'],
        zipfile = "{ref}_info.zip",
    shell:
        """
        if [ -z "{params.info}" ] || [ ! -f "{params.info}" ]; then
            echo "Info file not found locally, downloading from NCBI"
            datasets download genome accession {params.ref} --filename {params.zipfile} --include seq-report || (echo "Warning: download info failed. Check accession or prepare locally.")
            unzip {params.zipfile} -d "{params.ref}_info"
            python scripts/json_parse.py {params.ref}_info/ncbi_dataset/data/{params.ref}/sequence_report.jsonl | sed '/accession/d;/MT/d' | awk '{{print $1",@_chr"$2}}' > {output.info}
            rm -r {params.zipfile} {params.ref}_info
        else
            echo "Using local genome file {params.info}"
            cp {params.info} {output.info}
        fi
        echo "Complete prepare_chromosome_reference"
        """

rule combine_filter_nanopore_fastq:
    input:
        nanopore_files = lambda wildcards: [f for dir in config["nanopore"][wildcards.sample]
                                            for f in glob.glob(f"{dir}/*.fastq.gz")]
    output:
        "results/{sample}/raws/{sample}_nanopore_5000.fastq.gz"
    threads: 5
    benchmark:
        "results/{sample}/benchmarks/01_{sample}_nanopore_combine_filter_fastq.bench"
    conda:
        "../envs/seqkit.yaml"
    shell:
        """
        if [ -z "{input}" ]; then
            echo "No nanopore fastq files found"
            exit
        fi
        for i in {input}; do
            cat $i
        done | seqkit sana | seqkit seq -m 5000 -Q 9 | seqkit rmdup -s -o {output}
        echo "The rule combine_filter_nanopore_fastq complete for sample {wildcards.sample}"
        """

rule combine_pacbio_fastq:
    input:
        pacbio_bam = lambda wildcards: [f for dir in config["pacbio"][wildcards.sample]
                                            for f in glob.glob(f"{dir}/*.bam")],
        pacbio_pbi = lambda wildcards: [f for dir in config["pacbio"][wildcards.sample]
                                            for f in glob.glob(f"{dir}/*.bam.pbi")]
    output:
        temp("fastq/{sample}_pacbio_raw.fastq.gz")
    threads: 8
    benchmark:
        "results/{sample}/benchmarks/01_{sample}_pacbio_combine_fastq.bench"
    conda:
        "../envs/bam2fastx.yaml"
    shell:
        """
        if [ -z {input.pacbio_bam} ]; then
            echo "No pacbio bam files found"
            exit
        fi
        bam2fastq -o fastq/{wildcards.sample}_pacbio_raw {input.pacbio_bam}
        echo "The rule combine_pacbio_fastq complete for sample {wildcards.sample}"
        """

rule filter_pacbio_fastq:
    input:
        "fastq/{sample}_pacbio_raw.fastq.gz"
    output:
        "results/{sample}/raws/{sample}_pacbio_5000.fastq.gz"
    threads: 5
    benchmark:
        "results/{sample}/benchmarks/01_{sample}_pacbio_filter_fastq.bench"
    conda:
        "../envs/seqkit.yaml"
    shell:
        """
        seqkit sana {input} | seqkit seq -m 5000 | seqkit rmdup -s -o {output}
        echo "The rule filter_pacbio_fastq complete for sample {wildcards.sample}"
        """

rule filtered_reads_stats:
    input:
        filtered = ancient("results/{sample}/raws/{sample}_{seqMachine}_5000.fastq.gz")
    output:
        filtered = "results/{sample}/info/{sample}_{seqMachine}_stat_filtered.txt",
    wildcard_constraints:
        seqMachine="(nanopore|pacbio)"
    threads: 5
    conda:
        "../envs/seqkit.yaml"
    benchmark:
        "results/{sample}/benchmarks/01_{sample}_{seqMachine}_fastq_filter_stats.bench"
    threads: 5
    shell:
        """
        seqkit stats --threads {threads} {input.filtered} > {output.filtered}
        echo "The rule filter_read_stats complete for sample {wildcards.sample} {wildcards.seqMachine}"
        """

rule hifiasmUL_de_novo:
    input:
        nano = "results/{sample}/raws/{sample}_nanopore_5000.fastq.gz",
        pac = "results/{sample}/raws/{sample}_pacbio_5000.fastq.gz",
    output:
        prima = "results/{sample}/hifiasm/{sample}_hybridPN.bp.p_ctg.gfa",
        hap1 = "results/{sample}/hifiasm/{sample}_hybridPN.bp.hap1.p_ctg.gfa",
        hap2 = "results/{sample}/hifiasm/{sample}_hybridPN.bp.hap2.p_ctg.gfa",
    conda:
        "../envs/hifiasm.yaml"
    log:
        "results/{sample}/logs/01_{sample}_hybridPN_hifiasm_denovo.log"
    threads: 20
    benchmark:
        "results/{sample}/benchmarks/02_{sample}_hybridPN_hifiasm_denovo_assembly.bench"
    shell:
        """
        hifiasm -o results/{wildcards.sample}/hifiasm/{wildcards.sample}_hybridPN -t {threads} --ul {input.nano} {input.pac} 2> {log}
        echo "The rule hifiasmUL_de_novo complete for sample {wildcards.sample}"
        """

rule gfa_to_fasta:
    input:
        prima = ancient("results/{sample}/hifiasm/{sample}_hybridPN.bp.p_ctg.gfa"),
        hap1 = ancient("results/{sample}/hifiasm/{sample}_hybridPN.bp.hap1.p_ctg.gfa"),
        hap2 = ancient("results/{sample}/hifiasm/{sample}_hybridPN.bp.hap2.p_ctg.gfa"),
    output:
        prima = "results/{sample}/intermediates/{sample}_hybridPN_denovo.fa",
        hap1 = "results/{sample}/intermediates/{sample}_hybridPN_denovo_hap1.fa",
        hap2 = "results/{sample}/intermediates/{sample}_hybridPN_denovo_hap2.fa",
    benchmark:
        "results/{sample}/benchmarks/02_{sample}_hybridPN_hifiasm_denovo_gfa_to_fasta.bench"
    shell:
        """
        awk '/^S/{{print ">"$2;print $3}}' {input.prima} | sed "s/ptg/{wildcards.sample}_hybridPN_hifiasmUL_/g" > {output.prima}
        awk '/^S/{{print ">"$2;print $3}}' {input.hap1} | sed "s/h1tg/{wildcards.sample}_hybridPN_hifiasmUL_hap1_/g" > {output.hap1}
        awk '/^S/{{print ">"$2;print $3}}' {input.hap2} | sed "s/h2tg/{wildcards.sample}_hybridPN_hifiasmUL_hap2_/g" > {output.hap2}
        """

rule contigs_quast:
    input:
        "results/{sample}/intermediates/{sample}_hybridPN_denovo.fa",
    output:
        "results/{sample}/info/{sample}_hybridPN_denovo_quast/report.tsv"
    conda:
        "../envs/quast.yaml"
    benchmark:
        "results/{sample}/benchmarks/02_{sample}_hybridPN_quast.bench"
    params:
        "results/{sample}/info/{sample}_hybridPN_denovo_quast/"
    shell:
        """
        quast.py {input} -o {params}
        echo "The rule contig_quast complete for sample {wildcards.sample}"
        """

rule ntlink_fasta:
    input:
        quast = "results/{sample}/info/{sample}_hybridPN_denovo_quast/report.tsv",
        fa = "results/{sample}/intermediates/{sample}_hybridPN_denovo.fa",
    output:
        temp("results/{sample}/intermediates/ntlink/{sample}_hybridPN_denovo.fa")
    shell:
        """
        cp {input.fa} {output}
        """

rule ntLink_grid_run:
    input:
        fa = "results/{sample}/intermediates/ntlink/{sample}_hybridPN_denovo.fa",
        nano = "results/{sample}/raws/{sample}_nanopore_5000.fastq.gz",
        pac = "results/{sample}/raws/{sample}_pacbio_5000.fastq.gz",
    output:
        fa = "results/{sample}/intermediates/ntlink/{sample}_hybridPN_denovo.fa.k{kval}.w{wval}.z1000.ntLink.scaffolds.gap_fill.fa",
    conda:
        "../envs/ntlink.yaml"
    threads: 10
    benchmark:
        "results/{sample}/benchmarks/03_{sample}_hybridPN_denovo_ntlink_k{kval}_w{wval}.bench"
    log:
        "results/{sample}/logs/02_{sample}_hybridPN_denovo_ntlink_k{kval}.w{wval}.log"
    shell:
        """
        ntLink scaffold gap_fill target={input.fa} reads="{input.nano} {input.pac}" t={threads} sensitive=True overlap=True extra_clean k={wildcards.kval} w={wildcards.wval} a=2 2> {log}

        filled=$(find "results/{wildcards.sample}/intermediates/ntlink/" -name "*gap_fill.fa" | wc -l)
        if [[ $filled -eq 9 ]]; then
            find "results/{wildcards.sample}/intermediates/ntlink/" \\( -name "{wildcards.sample}*tsv" -o -name "{wildcards.sample}*trim*" -o -name "{wildcards.sample}*aby*" \\) -exec rm {{}} + 
        fi
        """

rule ntlink_least_contigs:
    input:
        expand("results/{{sample}}/intermediates/ntlink/{{sample}}_hybridPN_denovo.fa.k{kval}.w{wval}.z1000.ntLink.scaffolds.gap_fill.fa", kval = KVALS, wval = WVALS),
    output:
        "results/{sample}/intermediates/{sample}_hybridPN_ntlink_least_contigs.txt"
    shell:
        """
        grep -c ">" {input} | sort -t ':' -k2 > {output}
        """

checkpoint extract_least_contigs:
    input:
        "results/{sample}/intermediates/{sample}_hybridPN_ntlink_least_contigs.txt"
    output:
        directory("results/{sample}/intermediates/{sample}_hybridPN_ntLink2")
    shell:
        """
        least_contigs=$(head -1 {input} | cut -d":" -f1)

        mkdir -p {output}
        cp $least_contigs {output}
        """

def ntlink_output(wildcards):
    checkpoint_output = checkpoints.extract_least_contigs.get(**wildcards).output[0]
    return expand("results/{sample}/intermediates/{sample}_hybridPN_ntLink2/{i}.fa",
               sample=wildcards.sample,
               i=glob_wildcards(os.path.join(checkpoint_output, "{i}.fa")).i)

rule ntlink_final:
    input:
        ntlink_output
    output:
        "results/{sample}/scaffolds/ntlink/{sample}_hybridPN_denovo_ntlink.fasta"
    shell:
        """
        cat {input} > {output}
        echo "The rule ntlink_final complete for sample {wildcards.sample}"
        """

rule primary_genome_ragTag:
    input:
        ref = ancient("reference/{ref}.fna"),
        fa = "results/{sample}/scaffolds/ntlink/{sample}_hybridPN_denovo_ntlink.fasta"
    output:
        "results/{sample}/scaffolds/ragtag/{ref}/{sample}_hybridPN_denovo_ntlink_ragtag_{ref}.fa"
    params:
        "results/{sample}/scaffolds/ragtag/{ref}/"
    threads: 10
    benchmark:
        "results/{sample}/benchmarks/04_{sample}_hybridPN_{ref}_ragtag.bench"
    conda:
        "../envs/ragtag.yaml"
    shell:
        """
        if [[ {wildcards.ref} != "none" ]]; then
            ragtag.py scaffold -t {threads} -o {params} -u {input.ref} {input.fa}
            sed 's/_RagTag//g' {params}"ragtag.scaffold.fasta" > {output}
        else
            cp {input.fa} {output}
        fi
        echo "Scaffold complete for sample {wildcards.sample} using {wildcards.ref}"
        """

rule haplo_genome_ragtag:
    input:
        ref = "reference/{ref}.fna",
        fa = ancient("results/{sample}/intermediates/{sample}_hybridPN_denovo_{hap}.fa"),
    output:
        "results/{sample}/scaffolds/ragtag/{ref}/{hap}/{sample}_hybridPN_denovo_{hap}.fa"
    params:
        "results/{sample}/scaffolds/ragtag/{ref}/{hap}/"
    threads: 10
    conda:
        "../envs/ragtag.yaml"
    benchmark:
        "results/{sample}/benchmarks/04_{sample}_hybridPN_{hap}_{ref}_ragtag.bench"
    shell:
        """
        if [[ {wildcards.ref} != "none" ]]; then
            ragtag.py scaffold -t {threads} -o {params} -u {input.ref} {input.fa}
            sed 's/_RagTag//g' {params}"ragtag.scaffold.fasta" > {output}
        else
            cp {input.fa} {output}
        fi
        """

rule accession_chromosome:
    input:
        ancient("reference/{ref}.info"),
    output:
        "results/{sample}/scaffolds/ragtag/{ref}/{sample}_{ref}_accs_chrs.txt"
    shell:
        """
        sed 's/@/{wildcards.sample}/g' {input} > {output}
        """

rule rename_scaffolds:
    input:
        acc = "results/{sample}/scaffolds/ragtag/{ref}/{sample}_{ref}_accs_chrs.txt",
        fa = "results/{sample}/scaffolds/ragtag/{ref}/{sample}_hybridPN_denovo_ntlink_ragtag_{ref}.fa"
    output:
        fa = "results/{sample}/scaffolds/{sample}_hybridPN_denovo_ntlink_{ref}.fa",
        acc = temp("{sample}_hybridPN_{ref}.temp")
    benchmark:
        "results/{sample}/benchmarks/04_{sample}_hybridPN_{ref}_rename_scaffolds.bench"
    shell:
        """
        awk -F',' '{{print $1}}' {input.acc} > {output.acc} 
        bash scripts/rename_awk.sh {output.acc} {wildcards.sample} {input.fa} {output.fa}
        while IFS="," read -r acc chrs; do
            sed "s/${{acc}}/${{chrs}}/g" -i {output.fa}
        done < {input.acc}
        """

rule rename_haplo_scaffolds:
    input:
        acc = "results/{sample}/scaffolds/ragtag/{ref}/{sample}_{ref}_accs_chrs.txt",
        fa = "results/{sample}/scaffolds/ragtag/{ref}/{hap}/{sample}_hybridPN_denovo_{hap}.fa"
    output:
        fa = "results/{sample}/scaffolds/{sample}_hybridPN_denovo_{hap}_{ref}.fa",
        acc = "{sample}_hybridPN_{ref}_{hap}.temp"
    benchmark:
        "results/{sample}/benchmarks/04_{sample}_hibridPN_{ref}_{hap}_rename_scaffolds.bench"
    shell:
        """
        awk -F',' '{{print $1}}' {input.acc} > {output.acc}
        bash scripts/rename_awk.sh {output.acc} {wildcards.sample} {input.fa} {output.fa}
        while IFS="," read -r acc chrs; do
            sed "s/${{acc}}/${{chrs}}_{wildcards.hap}/g" -i {output.fa}
        done < {input.acc}
        """

rule primary_genome_liftOff:
    input:
        genome = ancient("reference/{ref}.fna"),
        gff = ancient("reference/{ref}.gff"),
        fa = "results/{sample}/scaffolds/{sample}_hybridPN_denovo_ntlink_{ref}.fa",
        chrInfo = "results/{sample}/scaffolds/ragtag/{ref}/{sample}_{ref}_accs_chrs.txt"
    output:
        temp = temp("results/{sample}/scaffolds/ragtag/{ref}/{sample}_hybridPN_denovo_ntlink_{ref}.gff"),
        chrs = temp("results/{sample}/scaffolds/ragtag/{ref}/{sample}_hybridPN_denovo_ntlink_{ref}_chrs.txt"),
        unmap = "results/{sample}/scaffolds/ragtag/{ref}/{sample}_hybridPN_denovo_ntlink_{ref}_liftoff_unmapped.txt",
        dir = temp(directory("results/{sample}/scaffolds/ragtag/{ref}/liftoff_hybridPN")),
    benchmark:
        "results/{sample}/benchmarks/05_{sample}_hybridPN_{ref}_liftoff.bench"
    conda:
        "../envs/liftoff.yaml"
    threads: 10
    shell:
        """
        if [[ {wildcards.ref} != "none" ]]; then
            grep ">" {input.fa} | grep "chr" | sed 's/>//g' | grep -f - {input.chrInfo} > {output.chrs}
            liftoff -g {input.gff} -o {output.temp} -p {threads} -u {output.unmap} -dir {output.dir} -chroms {output.chrs} {input.fa} {input.genome}
        else
            touch {output.temp} {output.unmap}
            mkdir -p {output.dir}
        fi
        """

rule primray_genome_gff_correct:
    input:
        "results/{sample}/scaffolds/ragtag/{ref}/{sample}_hybridPN_denovo_ntlink_{ref}.gff",
    output:
        gff = "results/{sample}/scaffolds/{sample}_hybridPN_denovo_ntlink_{ref}.gff",
    benchmark:
        "results/{sample}/benchmarks/05_{sample}_hybridPN_{ref}_liftoff_correct.bench"
    conda:
        "../envs/genometools.yaml"
    shell:
        """
        gt gff3 -sort -tidy -retainids {input} > {output}
        echo "Complete liftoff analysis of sample {wildcards.sample} scaffolds"
        """

rule scaffold_quast:
    input:
        "results/{sample}/scaffolds/{sample}_hybridPN_denovo_ntlink_{ref}.fa",
    output:
        "results/{sample}/info/{sample}_hybridPN_denovo_ntlink_{ref}_quast/report.tsv"
    conda:
        "../envs/quast.yaml"
    benchmark:
        "results/{sample}/benchmarks/06_{sample}_hybridPN_{ref}_quast_final.bench"
    params:
        "results/{sample}/info/{sample}_hybridPN_denovo_ntlink_{ref}_quast/"
    shell:
        """
        quast.py {input} -o {params}
        echo "Complete quast analysis of sample {wildcards.sample} scaffolds"
        """

rule reference_quast:
    input:
        "reference/{ref}.fna",
    output:
        "reference/{ref}_quast/report.tsv"
    conda:
        "../envs/quast.yaml"
    params:
        "reference/{ref}_quast/"
    shell:
        """
        quast.py {input} -o {params}
        """

checkpoint scaffold_busco:
    input:
        "results/{sample}/scaffolds/{sample}_hybridPN_denovo_ntlink_{ref}.fa"
    output:
        busco_dir = directory("results/{sample}/info/{sample}_hybridPN_denovo_ntlink_{ref}_busco/"),
    conda:
        "../envs/busco.yaml"
    log:
        "results/{sample}/logs/03_{sample}_hybridPN_denovo_ntlink_ragtag_{ref}_busco.log"
    benchmark:
        "results/{sample}/benchmarks/06_{sample}_hybridPN_{ref}_busco.bench"
    params:
        busco = config["busco"],       
    threads: 20
    shell:
        """
        busco -m genome -i {input} -o {output.busco_dir} -l {params} -c {threads} -f 2> {log}
        echo "Complete BUSCO analysis of sample {wildcards.sample} scaffolds"
        """

checkpoint reference_busco:
    input:
        "reference/{ref}.fna"
    output:
        "reference/{ref}_busco/",
    conda:
        "../envs/busco.yaml"
    params:
        busco = config["busco"],
    threads: 20
    shell:
        """
        busco -m genome -i {input} -o {output} -l {params.busco} -c {threads} -f 
        """

def scaffold_busco_output(wildcards):
    checkpoint_output = checkpoints.scaffold_busco.get(**wildcards).output[0]
    return expand("results/{sample}/info/{sample}_hybridPN_denovo_ntlink_{ref}_busco/short_summary.{i}_busco.txt",
                sample = wildcards.sample,
                ref=wildcards.ref,
                i=glob_wildcards(os.path.join(checkpoint_output, "short_summary.{i}_busco.txt")).i)

def reference_busco_output(wildcards):
    checkpoint_output = checkpoints.reference_busco.get(**wildcards).output[0]
    return expand("reference/{ref}_busco/short_summary.{i}_busco.txt",
                ref=wildcards.ref,
                i=glob_wildcards(os.path.join(checkpoint_output, "short_summary.{i}_busco.txt")).i)

rule busco_directory:
    input:
        ref = reference_busco_output,
        scaffold = scaffold_busco_output
    output:
        directory("results/{sample}/info/compare_{sample}_{ref}_busco/")
    shell:
        """
        mkdir -p {output}
        cp {input} {output}
        """

rule busco_final_figure:
    input:
        file = "results/{sample}/info/{sample}_vs_{ref}_busco.txt",
        outdir ="results/{sample}/info/compare_{sample}_{ref}_busco/"
    output:
        "results/{sample}/info/compare_{sample}_{ref}_figure.png"
    conda:
        "../envs/busco.yaml"
    benchmark:
        "results/{sample}/benchmarks/06_{sample}_hybridPN_{ref}_busco_image.bench"
    shell:
        """
        generate_plot.py --working_directory {input.outdir}
        mv {input.outdir}/busco_figure.png {output}
        """

rule busco_compare:
    input:
        ref = reference_busco_output,
        scaffold = scaffold_busco_output
    output:
        "results/{sample}/info/{sample}_vs_{ref}_busco.txt"
    shell:
        """
        custom_array=("Complete" "Complete_and_single-copy" "Complete_and_duplicated" "Fragmented" "Missing" "Total")
        (echo "Description, {wildcards.ref}, {wildcards.sample}"; paste <(grep "Result" -A 8 {input.ref} | tail -6 | awk '{{print $1}}') <(grep "Result" -A 8 {input.scaffold} | tail -6 | awk '{{print $1}}')  | awk -v arr="${{custom_array[*]}}" 'BEGIN {{split(arr, a, " ")}} {{printf "%s, %s, %s\\n", a[NR], $1, $2}}') > {output}
        """

rule final_quast:
    input:
        contig_quast = "reference/{ref}_quast/report.tsv",
        scaffold_quast = "results/{sample}/info/{sample}_hybridPN_denovo_ntlink_{ref}_quast/report.tsv"
    output:
        stats = "results/{sample}/info/{sample}_hybridPN_denovo_ntlink_ragtag_{ref}_stats.csv"
    benchmark:
        "results/{sample}/benchmarks/06_{sample}_hybridPN_{ref}_stats_collect.bench"
    shell:
        """
        grep "Assembly" {input.contig_quast} | awk '{{print $2}}' > {output}
        grep "contigs (>= 0 bp)" {input.contig_quast} | awk -F"\t" '{{print $2}}' >> {output}
        grep "N50" {input.contig_quast} | awk '{{print $2}}' >> {output}
        grep "contigs (>= 0 bp)" {input.scaffold_quast} | awk -F"\t" '{{print $2}}' >> {output}
        grep "N50" {input.scaffold_quast} | awk '{{print $2}}' >> {output}
        """

rule download_flanking_genes:
    params:
        left = lambda wildcards: REGIONS[wildcards.region]['left_flank'],
        right = lambda wildcards: REGIONS[wildcards.region]['right_flank'],
        ref = config['species']
    threads: 10
    output:
        temp = temp("flanking_genes/{species}/temp_{region}.fa"),
        final = "flanking_genes/{species}/{region}.fasta",
        info = "flanking_genes/{species}/info_{region}.txt"
    retries: 3
    conda:
        "../envs/flanking.yaml"
    shell:
        """
        left_flank={params.left}
        touch {output.info}

        if [[ ! -z $left_flank ]]; then
            datasets download gene symbol {params.left} --taxon "{params.ref}" --include gene --filename {params.left}.zip || (echo "Warning: Download left flanking failed! Check if gene or sepecies is correct.")
            unzip {params.left}.zip -d {params.left}
            cat {params.left}/ncbi_dataset/data/gene.fna >> {output.temp}
            rm -r {params.left} {params.left}.zip
            echo "left:" {params.left} >> {output.info}
            sleep 3
        fi

        right_flank={params.right}
        # Right flanking gene
        if [[ ! -z $right_flank ]]; then
            datasets download gene symbol {params.right} --taxon "{params.ref}" --include gene --filename {params.right}.zip || (echo "Warning: Download right flanking failed! Check if gene or sepecies is correct.")
            unzip {params.right}.zip -d {params.right}
            cat {params.right}/ncbi_dataset/data/gene.fna >> {output.temp}
            rm -r {params.right}/ {params.right}.zip
            echo "right:" {params.right} >> {output.info}
            sleep 2
        fi
        
        sed -E "s/ \\[.*//g;s/ /_/g" {output.temp} > {output.final}
        echo "Complete download flanking gene"
        """

rule locate_flanking_genes:
    input:
        fa = "results/{sample}/scaffolds/{sample}_hybridPN_denovo_{hap}_{ref}.fa",
        flanks = "flanking_genes/{species}/{region}.fasta"
    output:
        sam = "map_temp/{species}/{sample}/{region}/{sample}_{hap}_{ref}_{region}_flank_genes.sam",
        flank_region = "map_temp/{species}/{sample}/{region}/{sample}_{hap}_{ref}_{region}_flank_genes.txt"
    benchmark:
        "results/{sample}/benchmarks/07_{sample}_{hap}_{species}_{ref}_{region}_1_map_flanking_genes.bench"
    threads: 6
    conda:
        "../envs/minimap2.yaml"
    shell:
        """
        minimap2 -ax asm5 -t {threads} {input.fa} {input.flanks} > {output.sam}
        cut -f1-5 {output.sam} | grep -v "@" | awk '$3!="*"' > {output.flank_region}
        echo "Mapped flanking gene to {wildcards.sample} {wildcards.hap}"
        """

checkpoint check_flanking_genes:
    input:
        loc = "map_temp/{species}/{sample}/{region}/{sample}_{hap}_{ref}_{region}_flank_genes.txt",
        info = "flanking_genes/{species}/info_{region}.txt"
    output:
        status = "results/{sample}/annotation/{region}/{hap}/{sample}_{hap}_{species}_{ref}_{region}_status.csv",
        tmp = temp("map_temp/{species}/{sample}/{region}/{sample}_{hap}_{ref}_{region}_status.tmp"),
    benchmark:
        "results/{sample}/benchmarks/07_{sample}_{hap}_{species}_{ref}_{region}_2_check_flanking_genes.bench"
    shell:
        """
        # Extract left and right flanking genes
        left_flank=$(grep 'left' {input.info} | awk -F': ' '{{print $2}}' || true)
        right_flank=$(grep 'right' {input.info} | awk -F': ' '{{print $2}}' || true)

        # Initialize variables to track the contigs for left and right flanking gene
        left_contigs=""
        right_contigs=""

        # Find contigs for left and right genes
        while IFS=$'\t' read -r region_info _ contig position _; do
            gene_name=$(echo $region_info | awk -F'_' '{{print $NF}}')

            if [ "$gene_name" = "$left_flank" ]; then
                left_contigs="$left_contigs $contig"
            elif [ "$gene_name" = "$right_flank" ]; then
                right_contigs="$right_contigs $contig"
            fi
        done < {input.loc}

        # Remove duplicates from the contig lists
        left_contigs=$(echo "$left_contigs" | tr ' ' '\n' | sort -u | tr '\n' ' ')
        right_contigs=$(echo "$right_contigs" | tr ' ' '\n' | sort -u | tr '\n' ' ')

        # Check if both flanking genes are found
        if [ -n "$left_flank" ] && [ -n "$right_flank" ]; then
            common_contigs=$(comm -12 <(echo "$left_contigs" | tr ' ' '\n' | grep -v '^$' | sort) <(echo "$right_contigs" | tr ' ' '\n' | grep -v '^$' | sort))
            # Find unique contigs to the left
            if [ -n "$common_contigs" ]; then
                for contig in $common_contigs; do
                    echo -e "flanks\tclosed\t$left_flank/$right_flank\t$contig" >> {output.tmp}
                done
            else
                left_unique=$(comm -23 <(echo "$left_contigs" | tr ' ' '\n' | grep -v '^$' | sort) <(echo "$right_contigs" | tr ' ' '\n' | grep -v '^$' | sort)| tr '\n' ' ')
                right_unique=$(comm -13 <(echo "$left_contigs" | tr ' ' '\n' | grep -v '^$' | sort) <(echo "$right_contigs" | tr ' ' '\n' | grep -v '^$' | sort)| tr '\n' ' ')

                if [[ -z "$left_unique" && -z "$right_unique" ]]; then
                    echo -e "flanks\tmissing\t*\t*" >> {output.tmp}
                else
                    echo -e "flanks\tfragmented\t$left_flank/$right_flank\t$left_unique/$right_unique" >> {output.tmp}
                fi
            fi
        elif [ -n "$left_flank" ]; then
            if [ -n "$left_contigs" ]; then

                for contig in $left_contigs; do
                    echo -e "telomere\tclosed\t$left_flank/\t$contig" >> {output.tmp}
                done    
            fi
        elif [ -n "$right_flank" ]; then
            if [ -n "$right_contigs" ]; then
                for contig in $left_contigs; do
                    echo -e "telomere\tclosed\t/$right_flank\t$contig" >> {output.tmp}
                done
            fi
        fi
        awk '!s[$0]++' {output.tmp} > {output.status}
        echo "Checking {wildcards.region} flanking genes on {wildcards.sample} {wildcards.hap}"
        """

rule region_sam_to_sort_bam:
    input:
        sam = "map_temp/{species}/{sample}/{region}/{sample}_{hap}_{ref}_{region}_flank_genes.sam",
    output:
        bam = temp("map_temp/{species}/{sample}/{region}/{sample}_{hap}_{ref}_{region}_flank_genes.bam"),
        sort = temp("map_temp/{species}/{sample}/{region}/{sample}_{hap}_{ref}_{region}_flank_genes_sort.bam"),
    benchmark:
        "results/{sample}/benchmarks/07_{sample}_{hap}_{species}_{ref}_{region}_3_sam_bam.bench"
    conda:
        "../envs/samtools.yaml"
    shell:
        """
        samtools view -@ {threads} -bh {input.sam} > {output.bam}
        samtools sort -@ {threads} -o {output.sort} {output.bam}
        """

rule region_intact_bed:
    input:
        sam = "map_temp/{species}/{sample}/{region}/{sample}_{hap}_{ref}_{region}_flank_genes.sam",
        bam = "map_temp/{species}/{sample}/{region}/{sample}_{hap}_{ref}_{region}_flank_genes_sort.bam",
        status = "results/{sample}/annotation/{region}/{hap}/{sample}_{hap}_{species}_{ref}_{region}_status.csv",
    output:
        bed = "results/{sample}/annotation/{region}/{hap}/{sample}_{hap}_{species}_{ref}_{region}_flanking_genes.bed",
        bed_mod = temp("map_temp/{species}/{sample}/{region}/{sample}_{hap}_{ref}_{region}_coords.tmp"),
        bed_final = "results/{sample}/annotation/{region}/{hap}/{sample}_{hap}_{species}_{ref}_{region}_region_coords.bed",
    benchmark:
        "results/{sample}/benchmarks/07_{sample}_{hap}_{species}_{ref}_{region}_4_roi_bed.bench"
    conda:
        "../envs/bedtools.yaml"
    shell:
        """
        # Convert to bed coords
        bedtools bamtobed -i {input.bam} > {output.bed}

        grep "closed" {input.status} |
        while IFS='\t' read -r flank_region flank_status genes contig; do
            if [[ "$flank_region" == "telomere" ]]; then
                # Can there be + and - strands together?
                strand=$(awk -v var="$contig" '$1==var {{print $6}}' {output.bed} | awk '!s[$0]++')
                echo $flank_region $flank_status $genes $contig $strand
                if [[ "$strand" == "+" ]]; then
                    end_coord=$(grep ":$contig\t" {input.sam} | grep "@" | awk -F'LN:' '{{print $2}}')
                    awk -v contig="$contig" -v endcoord="$end_coord" '$1==contig {{print $1"\t"$2"\t"endcoord"\t"$4"\t"$5"\t"$6}}' {output.bed} >> {output.bed_mod}
                else
                    awk '{{ print $1"\t0\t"$3"\t"$4"\t"$5"\t"$6}}' {output.bed} >> {output.bed_mod}
                fi
            else
            # Process closed flank region 
                # Smallest start and largest end
                awk -v var="$contig" '$1==var' {output.bed} |
                awk -v regin="{wildcards.region}" -F'\t' '{{
                  if (!start[$1] || $2 < start[$1]) {{
                    start[$1] = $2
                    region[$1] = regin
                    value[$1] = $5
                    strand[$1] = $6
                  }}
                  if (!end[$1] || $3 > end[$1]) {{
                    end[$1] = $3
                  }}
                }}
                END {{
                  for (key in start) {{
                    print key "\t" start[key] "\t" end[key] "\t" region[key] "\t" value[key] "\t" strand[key]
                  }}
                }}' >> {output.bed_mod}
            fi 
        done
        awk '!s[$2,$3]++' {output.bed_mod} > {output.bed_final}
        echo "Extract region with the flanking gene for {wildcards.sample} {wildcards.hap}"
        """

rule region_intact_contig:
    input:
        bed = "results/{sample}/annotation/{region}/{hap}/{sample}_{hap}_{species}_{ref}_{region}_region_coords.bed",
        fa = "results/{sample}/scaffolds/{sample}_hybridPN_denovo_{hap}_{ref}.fa",
    output:
        fa = "results/{sample}/annotation/{region}/{hap}/{sample}_{hap}_{species}_{ref}_{region}_intact.fa",
    benchmark:
        "results/{sample}/benchmarks/07_{sample}_{hap}_{species}_{ref}_{region}_5_roi_contig.bench"
    conda:
        "../envs/bedtools.yaml"
    shell:
        """
        bedtools getfasta -fi {input.fa} -bed {input.bed} -s | sed 's/:.*/_{wildcards.region}/g' > {output.fa}
        echo "Extract intact {wildcards.region} region with the flanking genes for {wildcards.sample} {wildcards.hap}"
        """

rule library_format:
    input:
        lambda wildcards: check_library(wildcards.region, config['region'][wildcards.region].get('library'))
    output:
        "map_temp/{species}/{sample}/{region}/library/{species}_{region}_lib.fasta"
    conda:
        "../envs/rename.yaml"
    shell:
        """
        python scripts/lib_format.py {input} | seqkit rmdup -s | sed 's/\\r//g' > {output}
        """

rule region_intact_minimap2:
    input:
        fa = "results/{sample}/annotation/{region}/{hap}/{sample}_{hap}_{species}_{ref}_{region}_intact.fa",
        lib = "map_temp/{species}/{sample}/{region}/library/{species}_{region}_lib.fasta",
    output:
        "map_temp/{species}/{sample}/{region}/library/{sample}_{hap}_{ref}_{region}_intact.paf",
    benchmark:
        "results/{sample}/benchmarks/07_{sample}_{hap}_{species}_{ref}_{region}_6_lib_maps_roi.bench"
    params:
        minimap2 = lambda wildcards: REGIONS[wildcards.region]['minimap2'],
    threads: 6
    conda:
        "../envs/minimap2.yaml"
    shell:
        """
        # mapping lib to region
        minimap2 {params} -c -t {threads} {input.fa} {input.lib} > {output}
        echo "Mapping {wildcards.region} to {wildcards.sample} {wildcards.hap}"
        """

rule region_intact_cigar_info:
    input:
        "map_temp/{species}/{sample}/{region}/library/{sample}_{hap}_{ref}_{region}_intact.paf",
    output:
        "results/{sample}/annotation/{region}/{hap}/{sample}_{hap}_{species}_{ref}_{region}_gene_coords_paf.txt"
    benchmark:
        "results/{sample}/benchmarks/07_{sample}_{hap}_{species}_{ref}_{region}_7_cigar_process.bench"
    shell:
        """
        python scripts/cigar_digest2.py {input} {output}
        echo "Processed paf file of {wildcards.sample} {wildcards.hap} for region {wildcards.region} {wildcards.hap}"
        """

rule region_intact_gene_blast:
    input:
        paf = "results/{sample}/annotation/{region}/{hap}/{sample}_{hap}_{species}_{ref}_{region}_gene_coords_paf.txt",
        fa = "results/{sample}/annotation/{region}/{hap}/{sample}_{hap}_{species}_{ref}_{region}_intact.fa",
        lib = lambda wildcards: REGIONS[wildcards.region]['library']
    output:
        "results/{sample}/annotation/{region}/{hap}/{sample}_{hap}_{species}_{ref}_{region}_gene_coords_paf.blast",
    benchmark:
        "results/{sample}/benchmarks/07_{sample}_{hap}_{species}_{ref}_{region}_8_gene_blast.bench"
    log:
        "results/{sample}/logs/07_{sample}_{hap}_{species}_{ref}_{region}_8_gene_blast.log"
    threads: 10
    conda:
        "../envs/bbstools.yaml"
    threads: 10
    params:
        blast = lambda wildcards: REGIONS[wildcards.region]['blast'],
    shell:
        """
        python scripts/paf_blast.py -p {input.paf} -r {input.lib} -f {input.fa} -o {output} &> {log}
        echo "Aligned {input.lib} to the intact {wildcards.region} region on {wildcards.sample} {wildcards.hap}."
        """

rule region_intact_join_blast_paf:
    input:
        info = "results/{sample}/annotation/{region}/{hap}/{sample}_{hap}_{species}_{ref}_{region}_gene_coords_paf.txt",
        blast = "results/{sample}/annotation/{region}/{hap}/{sample}_{hap}_{species}_{ref}_{region}_gene_coords_paf.blast",
    output:
        "results/{sample}/annotation/{region}/{hap}/{sample}_{hap}_{species}_{ref}_{region}_candidates.tsv"
    benchmark:
        "results/{sample}/benchmarks/07_{sample}_{hap}_{species}_{ref}_{region}_9_blast_paf_merge.bench"
    shell:
        """
        python scripts/blast_extraction.py -i {input.info} -b {input.blast} -o {output}
        echo "Combined paf and blast files for {wildcards.region} region of {wildcards.sample} {wildcards.hap}"
        """

rule region_intact_filter:
    input:
        "results/{sample}/annotation/{region}/{hap}/{sample}_{hap}_{species}_{ref}_{region}_candidates.tsv"
    output:
        "results/{sample}/annotation/{region}/{hap}/{sample}_{hap}_{species}_{ref}_{region}_filter.tsv"
    benchmark:
        "results/{sample}/benchmarks/07_{sample}_{hap}_{species}_{ref}_{region}_10_filter.bench"
    shell:
        """
        python scripts/filter_query_ident.py -i {input} -o {output}
        echo "Filter genes for {wildcards.region} region on sample {wildcards.sample} {wildcards.hap}"
        """

rule region_intact_accurate_coords:
    input:
        filtr = "results/{sample}/annotation/{region}/{hap}/{sample}_{hap}_{species}_{ref}_{region}_filter.tsv",
        bed = "results/{sample}/annotation/{region}/{hap}/{sample}_{hap}_{species}_{ref}_{region}_flanking_genes.bed",
    output:
        "results/{sample}/annotation/{region}/{hap}/intact/{sample}_{hap}_{species}_{ref}_{region}_final.tsv"
    benchmark:
        "results/{sample}/benchmarks/07_{sample}_{hap}_{species}_{ref}_{region}_11_coords_correct.bench"
    shell:
        """
        python scripts/coord_correction.py -b {input.bed} -f {input.filtr} -o {output}
        """

rule region_intact_figure:
    input:
        "results/{sample}/annotation/{region}/{hap}/intact/{sample}_{hap}_{species}_{ref}_{region}_final.tsv"
    conda:
        "../envs/dna_viewer.yaml"
    output:
        "results/{sample}/annotation/{region}/{hap}/intact/{sample}_{hap}_{species}_{ref}_{region}.svg"
    params:
        "results/{sample}/annotation/{region}/{hap}/intact/{sample}_{hap}_{species}_{ref}_{region}"
    benchmark:
        "results/{sample}/benchmarks/07_{sample}_{hap}_{species}_{ref}_{region}_12_figure.bench"
    shell:
        """
        python scripts/dna_viewer_table.py -i {input} -o {params}
        """

rule fragment_region:
    output:
        touch("regions/{species}/{sample}/{region}/fragmented/{sample}_{hap}_{ref}_{region}.done")
    shell:
        """
        echo "The region {wildcards.region} of sample {wildcards.sample} {wildcards.hap} was fragmented."
        """

rule missing_region:
    output:
        touch("regions/{species}/{sample}/{region}/missing/{sample}_{hap}_{ref}_{region}.done")

def check_gaps(wildcards):
    with checkpoints.check_flanking_genes.get(**wildcards).output[0].open() as f:
        for line in f:
            col1, col2, col3, col4 = line.strip().split("\t")
            if col2 == "closed":
                return "results/{sample}/annotation/{region}/{hap}/intact/{sample}_{hap}_{species}_{ref}_{region}.svg"
            elif col2 == "fragmented":
                return "regions/{species}/{sample}/{region}/fragmented/{sample}_{hap}_{ref}_{region}.done"
            else:
                return "regions/{species}/{sample}/{region}/missing/{sample}_{hap}_{ref}_{region}.done"

rule region_annotation:
    input:
        check_gaps
    output:
        "results/{sample}/annotation/{region}/{hap}/{sample}_{hap}_{species}_{ref}_{region}_annotation.finish"
    shell:
        "cat {input} > {output}"

rule annotation_done:
    input:
        expand("results/{{sample}}/annotation/{region}/{hap}/{{sample}}_{hap}_{{species}}_{{ref}}_{region}_annotation.finish", hap = ['hap1','hap2'], region = REGIONS)
    output:
        touch("results/{sample}/annotation/{sample}_{species}_{ref}_final_annotation.finish")

rule filtered_raw_stats:
    input:
        nanopore = "results/{sample}/info/{sample}_nanopore_stat_filtered.txt",
        pacbio = "results/{sample}/info/{sample}_pacbio_stat_filtered.txt",
    output:
        "results/{sample}/info/{sample}_filtered_reads_stats.txt"
    shell:
        """
        echo "file num_seqs sum_len min_len avg_len max_len" > {output}
        cat {input} | sed '/file/d' | awk '{{print $1,$4,$5,$6,$7,$8}}' | sed 's/.*\\///g;s/,//g' >> {output}
        """

rule prepare_report:
    input:
        "scripts/final_report_blank2.Rmd"
    output:
        "results/{sample}/info/{sample}_report.Rmd"
    shell:
        """
        cp {input} {output}
        """

rule full_report:
    input:
        sc = "results/{sample}/info/{sample}_report.Rmd",
        stats = "results/{sample}/info/{sample}_hybridPN_denovo_ntlink_ragtag_{ref}_stats.csv",
        raw_stats = "results/{sample}/info/{sample}_filtered_reads_stats.txt",
        annotate = "results/{sample}/annotation/{sample}_{species}_{ref}_final_annotation.finish",
        busco = "results/{sample}/info/compare_{sample}_{ref}_figure.png",
    output:
        html = "results/{sample}/info/{sample}_{ref}_{species}_report.html"
    conda:
        "../envs/report.yaml"
    params:
        "results/{sample}/info/"
    log:
        "results/{sample}/logs/{sample}_{ref}_{species}_report.log"
    shell:
        """
        Rscript -e "rmarkdown::render('{input.sc}', output_dir = '{params}', output_file=paste0('{wildcards.sample}_{wildcards.ref}_{wildcards.species}','_report'), output_format='html_document',params=list(subject='{wildcards.sample}',reference='{wildcards.ref}',species='{wildcards.species}'))" 2> {log}
        echo "Final report generated"
        """






onsuccess:
    shell("""
        echo "Complete analysis"
    """)
